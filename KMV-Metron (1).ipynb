{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c7d989",
   "metadata": {},
   "source": [
    "# KMV-Metron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1049f1",
   "metadata": {},
   "source": [
    "# Descriptive Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05cfd",
   "metadata": {},
   "source": [
    "## Before Crisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b0b3e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Year_2005  Year_2006  Year_2007\n",
      "count     21.000000  21.000000  21.000000\n",
      "mean       0.018095   0.031429   0.132857\n",
      "std        0.082923   0.095618   0.268312\n",
      "min        0.000000   0.000000   0.000000\n",
      "25%        0.000000   0.000000   0.000000\n",
      "50%        0.000000   0.000000   0.000000\n",
      "75%        0.000000   0.000000   0.050000\n",
      "max        0.380000   0.400000   0.900000\n",
      "median     0.000000   0.000000   0.000000\n",
      "iqr        0.000000   0.000000   0.050000\n",
      "skewness   4.582576   3.433987   2.203892\n",
      "kurtosis  21.000000  12.069488   3.884093\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_df = df.drop(columns=['Bank'])\n",
    "\n",
    "# Descriptive statistics\n",
    "descriptive_stats = numeric_df.describe()\n",
    "\n",
    "# Include additional parameters\n",
    "median = numeric_df.median()\n",
    "iqr = numeric_df.quantile(0.75) - numeric_df.quantile(0.25)\n",
    "skewness = numeric_df.skew()\n",
    "kurtosis = numeric_df.kurtosis()\n",
    "\n",
    "# Add additional parameters to descriptive statistics DataFrame\n",
    "descriptive_stats.loc['median'] = median\n",
    "descriptive_stats.loc['iqr'] = iqr\n",
    "descriptive_stats.loc['skewness'] = skewness\n",
    "descriptive_stats.loc['kurtosis'] = kurtosis\n",
    "\n",
    "# Print descriptive statistics\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7600b1a",
   "metadata": {},
   "source": [
    "## During Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a51945da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Year_2008\n",
      "count     21.000000\n",
      "mean       0.186190\n",
      "std        0.131662\n",
      "min        0.000000\n",
      "25%        0.110000\n",
      "50%        0.150000\n",
      "75%        0.200000\n",
      "max        0.600000\n",
      "median     0.150000\n",
      "iqr        0.090000\n",
      "skewness   1.742830\n",
      "kurtosis   3.950446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "   'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_df = df.drop(columns=['Bank'])\n",
    "\n",
    "# Descriptive statistics\n",
    "descriptive_stats = numeric_df.describe()\n",
    "\n",
    "# Include additional parameters\n",
    "median = numeric_df.median()\n",
    "iqr = numeric_df.quantile(0.75) - numeric_df.quantile(0.25)\n",
    "skewness = numeric_df.skew()\n",
    "kurtosis = numeric_df.kurtosis()\n",
    "\n",
    "# Add additional parameters to descriptive statistics DataFrame\n",
    "descriptive_stats.loc['median'] = median\n",
    "descriptive_stats.loc['iqr'] = iqr\n",
    "descriptive_stats.loc['skewness'] = skewness\n",
    "descriptive_stats.loc['kurtosis'] = kurtosis\n",
    "\n",
    "# Print descriptive statistics\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863986c3",
   "metadata": {},
   "source": [
    "## After Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4919bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Year_2009  Year_2010  Year_2011  Year_2012  Year_2013  Year_2014\n",
      "count     21.000000  21.000000  21.000000  21.000000  21.000000  21.000000\n",
      "mean       0.099524   0.090095   0.095238   0.090000   0.018571   0.173333\n",
      "std        0.201233   0.215714   0.140486   0.213002   0.029204   0.362206\n",
      "min        0.000000   0.000000   0.000000   0.000000   0.000000   0.000000\n",
      "25%        0.010000   0.015000   0.010000   0.000000   0.000000   0.000000\n",
      "50%        0.020000   0.020000   0.030000   0.020000   0.000000   0.000000\n",
      "75%        0.090000   0.060000   0.100000   0.080000   0.030000   0.030000\n",
      "max        0.910000   1.000000   0.540000   0.990000   0.090000   1.000000\n",
      "median     0.020000   0.020000   0.030000   0.020000   0.000000   0.000000\n",
      "iqr        0.080000   0.045000   0.090000   0.080000   0.030000   0.030000\n",
      "skewness   3.612331   4.127193   2.230282   4.133416   1.447030   1.920545\n",
      "kurtosis  14.357021  17.898502   4.789739  18.041585   0.821122   2.085613\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "   'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "   'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02],\n",
    "    'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03]\n",
    "    \n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_df = df.drop(columns=['Bank'])\n",
    "\n",
    "# Descriptive statistics\n",
    "descriptive_stats = numeric_df.describe()\n",
    "\n",
    "# Include additional parameters\n",
    "median = numeric_df.median()\n",
    "iqr = numeric_df.quantile(0.75) - numeric_df.quantile(0.25)\n",
    "skewness = numeric_df.skew()\n",
    "kurtosis = numeric_df.kurtosis()\n",
    "\n",
    "# Add additional parameters to descriptive statistics DataFrame\n",
    "descriptive_stats.loc['median'] = median\n",
    "descriptive_stats.loc['iqr'] = iqr\n",
    "descriptive_stats.loc['skewness'] = skewness\n",
    "descriptive_stats.loc['kurtosis'] = kurtosis\n",
    "\n",
    "# Print descriptive statistics\n",
    "print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695c13b",
   "metadata": {},
   "source": [
    "# KMV Metro Prediction Using Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8680be5",
   "metadata": {},
   "source": [
    "## Before Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1cecde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 86.66666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "data = {\n",
    "    \n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracies = []\n",
    "type1_errors = []\n",
    "type2_errors = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2005', 'Year_2006', 'Year_2007']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[: ,1]\n",
    "    \n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "   # confusion = confusion_matrix(y_test, y_pred)\n",
    "    #type1_error = confusion[0, 1] / confusion.sum(axis=1)[0]  # False positive rate\n",
    "    #type2_error = confusion[1, 0] / confusion.sum(axis=1)[1]  # False negative rate\n",
    "    \n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "   # type1_errors.append(type1_error)\n",
    "   # type2_errors.append(type2_error)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "#avg_type1_error = np.mean(type1_errors)\n",
    "#avg_type2_error = np.mean(type2_errors)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Accuracy:\", avg_accuracy*100)\n",
    "#print(\"Average Type 1 Error (False Positive Rate):\", avg_type1_error)\n",
    "#rint(\"Average Type 2 Error (False Negative Rate):\", avg_type2_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "380d3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Year_2005 :\n",
      " [[5]]\n",
      "Confusion Matrix for Year_2006 :\n",
      " [[4 0]\n",
      " [1 0]]\n",
      "Confusion Matrix for Year_2007 :\n",
      " [[4 0]\n",
      " [1 0]]\n",
      "Average Accuracy: 86.66666666666667\n",
      "Average Type 1 Error (False Positive Rate): 0.0\n",
      "Average Type 2 Error (False Negative Rate): 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Before crisis\n",
    "data = {\n",
    "   \n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "  \n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracies = []\n",
    "type1_errors = []\n",
    "type2_errors = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2005', 'Year_2006', 'Year_2007']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix for\", year, \":\\n\", confusion)  # Debugging statement\n",
    "    \n",
    "    # Calculate type 1 and type 2 errors\n",
    "    if confusion.shape[1] > 1:\n",
    "        type1_error = confusion[0, 1] / (confusion[0, 0] + confusion[0, 1]) if np.sum(confusion[0]) > 0 else 0  # False positive rate\n",
    "        type2_error = confusion[1, 0] / (confusion[1, 0] + confusion[1, 1]) if np.sum(confusion[1]) > 0 else 0  # False negative rate\n",
    "    else:\n",
    "        type1_error = 0\n",
    "        type2_error = 0\n",
    "    \n",
    "    # Append errors to lists\n",
    "    type1_errors.append(type1_error)\n",
    "    type2_errors.append(type2_error)\n",
    "\n",
    "# Calculate average errors\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_type1_error = np.mean(type1_errors)\n",
    "avg_type2_error = np.mean(type2_errors)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Accuracy:\", avg_accuracy*100)\n",
    "print(\"Average Type 1 Error (False Positive Rate):\", avg_type1_error*100)\n",
    "print(\"Average Type 2 Error (False Negative Rate):\", avg_type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4760d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Year_2005 because there's only one class in y_test\n",
      "Average Sensitivity (Recall): 0.0\n",
      "Average AUC (Area Under the ROC Curve): 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score\n",
    "\n",
    "\n",
    "data = {\n",
    "     'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "  \n",
    "}\n",
    "\n",
    "   \n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivities = []\n",
    "aucs = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2005', 'Year_2006', 'Year_2007']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities of positive class\n",
    "    \n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = recall_score(y_test, model.predict(X_test))\n",
    "    sensitivities.append(sensitivity)\n",
    "    \n",
    "    # Check if there's only one class in y_test\n",
    "    unique_classes = np.unique(y_test)\n",
    "    if len(unique_classes) == 1:\n",
    "        print(f\"Skipping {year} because there's only one class in y_test\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    aucs.append(auc)\n",
    "\n",
    "# Calculate average sensitivities and AUCs\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_auc = np.mean(aucs)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Sensitivity (Recall):\", avg_sensitivity*10)\n",
    "print(\"Average AUC (Area Under the ROC Curve):\", avg_auc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1289d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Year_2005 because there's only one class in y_test\n",
      "Average Specificity: 100.0\n",
      "Average AUC (Area Under the ROC Curve): 68.75\n",
      "Average Brier Score: 17.02661165359261\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss\n",
    "\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "  \n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "specificities = []\n",
    "aucs = []\n",
    "brier_scores = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2005', 'Year_2006', 'Year_2007']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities of positive class\n",
    "    \n",
    "    # Check if there are both positive and negative classes in the test set\n",
    "    unique_classes = np.unique(y_test)\n",
    "    if len(unique_classes) < 2:\n",
    "        print(f\"Skipping {year} because there's only one class in y_test\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate specificity if there are both positive and negative classes\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, model.predict(X_test)).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    aucs.append(auc)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "    brier_scores.append(brier_score)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_auc = np.mean(aucs)\n",
    "avg_brier_score = np.mean(brier_scores)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Specificity:\", avg_specificity*100)\n",
    "print(\"Average AUC (Area Under the ROC Curve):\", avg_auc*100)\n",
    "print(\"Average Brier Score:\", avg_brier_score*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65886d56",
   "metadata": {},
   "source": [
    "## During Crisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d8a9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Year_2008 :\n",
      " [[0 2]\n",
      " [0 3]]\n",
      "Confusion Matrix for Year_2009 :\n",
      " [[4 0]\n",
      " [1 0]]\n",
      "Average Accuracy: 70.0\n",
      "Average Type 1 Error (False Positive Rate): 50.0\n",
      "Average Type 2 Error (False Negative Rate): 50.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "data = {\n",
    "  'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15],\n",
    "    'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracies = []\n",
    "type1_errors = []\n",
    "type2_errors = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2008', 'Year_2009']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix for\", year, \":\\n\", confusion)  # Debugging statement\n",
    "    \n",
    "    # Calculate type 1 and type 2 errors\n",
    "    if confusion.shape[1] > 1:\n",
    "        type1_error = confusion[0, 1] / (confusion[0, 0] + confusion[0, 1]) if np.sum(confusion[0]) > 0 else 0  # False positive rate\n",
    "        type2_error = confusion[1, 0] / (confusion[1, 0] + confusion[1, 1]) if np.sum(confusion[1]) > 0 else 0  # False negative rate\n",
    "    else:\n",
    "        type1_error = 0\n",
    "        type2_error = 0\n",
    "    \n",
    "    # Append errors to lists\n",
    "    type1_errors.append(type1_error)\n",
    "    type2_errors.append(type2_error)\n",
    "\n",
    "# Calculate average errors\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_type1_error = np.mean(type1_errors)\n",
    "avg_type2_error = np.mean(type2_errors)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Accuracy:\", avg_accuracy*100)\n",
    "print(\"Average Type 1 Error (False Positive Rate):\", avg_type1_error*100)\n",
    "print(\"Average Type 2 Error (False Negative Rate):\", avg_type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "290e952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sensitivity (Recall): 50.0\n",
      "Average AUC (Area Under the ROC Curve): 100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score\n",
    "\n",
    "data = {\n",
    "     'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15],\n",
    "    'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02]\n",
    "}\n",
    "\n",
    "   \n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivities = []\n",
    "aucs = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2008', 'Year_2009']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities of positive class\n",
    "    \n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = recall_score(y_test, model.predict(X_test))\n",
    "    sensitivities.append(sensitivity)\n",
    "    \n",
    "    # Check if there's only one class in y_test\n",
    "    unique_classes = np.unique(y_test)\n",
    "    if len(unique_classes) == 1:\n",
    "        print(f\"Skipping {year} because there's only one class in y_test\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    aucs.append(auc)\n",
    "\n",
    "# Calculate average sensitivities and AUCs\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_auc = np.mean(aucs)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Sensitivity (Recall):\", avg_sensitivity*100)\n",
    "print(\"Average AUC (Area Under the ROC Curve):\", avg_auc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d40050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Specificity: 50.0\n",
      "Average AUC (Area Under the ROC Curve): 100.0\n",
      "Average Brier Score: 23.635714643376122\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15],\n",
    "    'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "specificities = []\n",
    "aucs = []\n",
    "brier_scores = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in ['Year_2008', 'Year_2009']:\n",
    "    # Prepare data for logistic regression\n",
    "    X = df.drop(['Bank', year], axis=1)\n",
    "    y = np.where(df[year] > 0.1, 1, 0)  # Threshold for default probability\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilities of positive class\n",
    "    \n",
    "    # Check if there are both positive and negative classes in the test set\n",
    "    unique_classes = np.unique(y_test)\n",
    "    if len(unique_classes) < 2:\n",
    "        print(f\"Skipping {year} because there's only one class in y_test\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate specificity if there are both positive and negative classes\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, model.predict(X_test)).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    specificities.append(specificity)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    aucs.append(auc)\n",
    "    \n",
    "    # Calculate Brier score\n",
    "    brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "    brier_scores.append(brier_score)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_specificity = np.mean(specificities)\n",
    "avg_auc = np.mean(aucs)\n",
    "avg_brier_score = np.mean(brier_scores)\n",
    "\n",
    "# Print results\n",
    "print(\"Average Specificity:\", avg_specificity*100)\n",
    "print(\"Average AUC (Area Under the ROC Curve):\", avg_auc*100)\n",
    "print(\"Average Brier Score:\", avg_brier_score*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf6416",
   "metadata": {},
   "source": [
    "## After Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c17bf0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0\n",
      "Type 1 Error (False Positive Rate): 0.0\n",
      "Type 2 Error (False Negative Rate): 100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare data for logistic regression\n",
    "X = df.drop(['Bank'], axis=1)  # Features are default probabilities for each year\n",
    "# Convert 'Bank' names to binary labels (1 if 'Bank I', 0 otherwise)\n",
    "y = df['Bank'].apply(lambda x: 1 if x == 'Bank I' else 0)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict labels on the whole dataset\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (confusion.diagonal() / confusion.sum(axis=1)).mean()  # Overall accuracy across all classes\n",
    "\n",
    "# Calculate type 1 and type 2 errors\n",
    "type1_error = confusion[0, 1] / confusion[0].sum()  # False positive rate\n",
    "type2_error = confusion[1, 0] / confusion[1].sum()  # False negative rate\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "print(\"Type 1 Error (False Positive Rate):\", type1_error*100)\n",
    "print(\"Type 2 Error (False Negative Rate):\", type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dfdb29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity at threshold 0.5 : 0.0\n",
      "Specificity at threshold 0.5 : 100.0\n",
      "Sensitivity (True Positive Rate): [0. 1. 1.]\n",
      "Specificity (True Negative Rate): [1. 1. 0.]\n",
      "AUC (Area Under the ROC Curve): 100.0\n",
      "Brier Score: 17.778178923240205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare data for logistic regression\n",
    "X = df.drop(['Bank'], axis=1)  # Features are default probabilities for each year\n",
    "# Convert 'Bank' names to binary labels (1 if 'Bank I', 0 otherwise)\n",
    "y = df['Bank'].apply(lambda x: 1 if x == 'Bank I' else 0)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "sensitivity = tpr\n",
    "specificity = 1 - fpr\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate Brier Score\n",
    "brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "# Calculate sensitivity and specificity at a particular threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "idx = np.where(thresholds >= threshold)[0][0]  # Find the index of the threshold closest to 0.5\n",
    "\n",
    "sensitivity_at_threshold = sensitivity[idx]\n",
    "specificity_at_threshold = specificity[idx]\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity at threshold\", threshold, \":\", sensitivity_at_threshold*100)\n",
    "print(\"Specificity at threshold\", threshold, \":\", specificity_at_threshold*100)\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity)\n",
    "print(\"Specificity (True Negative Rate):\", specificity)\n",
    "print(\"AUC (Area Under the ROC Curve):\", auc*100)\n",
    "print(\"Brier Score:\", brier_score*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a1b58df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sensitivity: [nan nan nan]\n",
      "Average Specificity: [1.   0.85 0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare data for logistic regression\n",
    "X = df.drop(['Bank'], axis=1)  # Features are default probabilities for each year\n",
    "# Convert 'Bank' names to binary labels (1 if 'Bank I', 0 otherwise)\n",
    "y = df['Bank'].apply(lambda x: 1 if x == 'Bank I' else 0)\n",
    "\n",
    "# Initialize lists to store sensitivity and specificity values\n",
    "sensitivity_values = []\n",
    "specificity_values = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "num_folds = 5  # Number of folds\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    sensitivity = tpr\n",
    "    specificity = 1 - fpr\n",
    "    \n",
    "    # Append sensitivity and specificity values to lists\n",
    "    sensitivity_values.append(sensitivity)\n",
    "    specificity_values.append(specificity)\n",
    "\n",
    "# Calculate the average sensitivity and specificity over all folds\n",
    "average_sensitivity = sum(sensitivity_values) / num_folds\n",
    "average_specificity = sum(specificity_values) / num_folds\n",
    "\n",
    "# Print the average sensitivity and specificity\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c8325",
   "metadata": {},
   "source": [
    "## Final Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "305fd2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Avg Accuracy  Type I Error  Type II Error  Senstivity   \n",
      "0  Before Crisis          86.6           0.0             66         0.0  \\\n",
      "1  During Crisis          70.0          50.0             50        50.0   \n",
      "2   After Crisis          50.0           0.0            100         0.0   \n",
      "\n",
      "   Specificity    AUC  Brier Score  \n",
      "0          100   68.7        17.02  \n",
      "1           50  100.0        23.63  \n",
      "2           85  100.0        17.70  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Time':['Before Crisis','During Crisis','After Crisis'],\n",
    "    'Avg Accuracy': [86.6, 70, 50],\n",
    "    'Type I Error': [0.0, 50, 0],\n",
    "    'Type II Error': [66, 50, 100],\n",
    "    'Senstivity':[0.0,50,0.0],\n",
    "    'Specificity': [100,50,85],\n",
    "     'AUC':[68.7 , 100,100],\n",
    "     'Brier Score': [17.02 , 23.63 , 17.7]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Time', 'Avg Accuracy', 'Type I Error','Type II Error','Senstivity','Specificity','AUC','Brier Score'])\n",
    "\n",
    "# Print the Dzzzz\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e623c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
