{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda9e693",
   "metadata": {},
   "source": [
    "#  With Labels and Features Distress and Non-Distress Banks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cd768",
   "metadata": {},
   "source": [
    "## Before Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c975b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.0\n",
      "Type 1 Error (False Positive Rate): 0.0\n",
      "Type 2 Error (False Negative Rate): 100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2005', 'Year_2006', 'Year_2007']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "type1_error = confusion[0, 1] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0  # False positive rate\n",
    "type2_error = confusion[1, 0] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0  # False negative rate\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "print(\"Type 1 Error (False Positive Rate):\", type1_error*100)\n",
    "print(\"Type 2 Error (False Negative Rate):\", type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e5c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (True Positive Rate): 0.0\n",
      "Specificity (True Negative Rate): 100.0\n",
      "AUC (Area Under the ROC Curve): 58.33333333333333\n",
      "Brier Score: 22.743794499361154\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, brier_score_loss\n",
    "\n",
    "data = {\n",
    "    'Bank': ['Bank A', 'Bank B', 'Bank C', 'Bank D', 'Bank E', 'Bank F', 'Bank G', 'Bank H', 'Bank I', 'Bank J','Bank I','Bank K','Bank 12','Bank 13','Bank 14','Bank 15','Bank 16','Bank 17','Bank 18','Bank 19','Bank 20'],\n",
    "    'Year_2005': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0 , 0, 0, 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0, 0.38],\n",
    "    'Year_2006': [0, 0.2, 0, 0.06, 0, 0, 0, 0, 0, 0, 0 , 0.4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    'Year_2007': [0.5, 0, 0.04, 0 , 0.29 , 0 ,0 , 0.05 ,0 ,0 ,0.01 ,0 ,0 ,0,0 ,0 ,0.9 , 0.05 ,0.01 ,0.14 ,0.8 ],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "   \n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2005', 'Year_2006', 'Year_2007']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate sensitivity (True Positive Rate)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "sensitivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0\n",
    "\n",
    "# Calculate specificity (True Negative Rate)\n",
    "specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0\n",
    "\n",
    "# Calculate AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_test == 'Yes', y_pred_proba)\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity*100)\n",
    "print(\"Specificity (True Negative Rate):\", specificity*100)\n",
    "print(\"AUC (Area Under the ROC Curve):\", auc*100)\n",
    "print(\"Brier Score:\", brier_score*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82295351",
   "metadata": {},
   "source": [
    "# During Crisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ddd49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.0\n",
      "Type 1 Error (False Positive Rate): 0.0\n",
      "Type 2 Error (False Negative Rate): 100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "     'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15],\n",
    "    'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2008', 'Year_2009']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "type1_error = confusion[0, 1] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0  # False positive rate\n",
    "type2_error = confusion[1, 0] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0  # False negative rate\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "print(\"Type 1 Error (False Positive Rate):\", type1_error*100)\n",
    "print(\"Type 2 Error (False Negative Rate):\", type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "866989d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (True Positive Rate): 0.0\n",
      "Specificity (True Negative Rate): 100.0\n",
      "AUC (Area Under the ROC Curve): 0.0\n",
      "Brier Score: 24.809722919736878\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, brier_score_loss\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Bank': ['Bank A', 'Bank B', 'Bank C', 'Bank D', 'Bank E', 'Bank F', 'Bank G', 'Bank H', 'Bank I', 'Bank J','Bank I','Bank K','Bank 12','Bank 13','Bank 14','Bank 15','Bank 16','Bank 17','Bank 18','Bank 19','Bank 20'],\n",
    "    'Year_2008': [0.6,0.08,0.17,0.15,0.31,0.15,0.15,0.37,0.17,0.35,0.16,0.06,0.26,0.11,0.12,0.11,0.14,0,0.2,0.10,0.15],\n",
    "    'Year_2009' : [0.21,0.01,0.09,0.18,0.03,0.02,0,0.29,0.02,0.02,0,0,0,0.91,0.09,0.05,0.02,0.01,0.07,0.05,0.02],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "   \n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2008', 'Year_2009']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate sensitivity (True Positive Rate)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "sensitivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0\n",
    "\n",
    "# Calculate specificity (True Negative Rate)\n",
    "specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0\n",
    "\n",
    "# Calculate AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_test == 'Yes', y_pred_proba)\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity*100)\n",
    "print(\"Specificity (True Negative Rate):\", specificity*100)\n",
    "print(\"AUC (Area Under the ROC Curve):\", auc*100)\n",
    "print(\"Brier Score:\", brier_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2f41a",
   "metadata": {},
   "source": [
    "# After Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e924b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.0\n",
      "Type 1 Error (False Positive Rate): 0.0\n",
      "Type 2 Error (False Negative Rate): 100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Bank': ['RBS', 'Credit Suisse', 'Deutsche Bank', 'Banco', 'Barclays','BBVA', 'BNP', 'CBK', 'Danske', 'Ereste', 'HSBC', 'Intensa','KBC', 'Lloyds', 'Nordea', 'Skanden', 'Societe', 'Handelsbanken','Swedbank', 'UBS', 'Unicredit'],\n",
    "     'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2010', 'Year_2011','Year_2012','Year_2013','Year_2014']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "type1_error = confusion[0, 1] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0  # False positive rate\n",
    "type2_error = confusion[1, 0] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0  # False negative rate\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "print(\"Type 1 Error (False Positive Rate):\", type1_error*100)\n",
    "print(\"Type 2 Error (False Negative Rate):\", type2_error*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e02c443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (True Positive Rate): 0.0\n",
      "Specificity (True Negative Rate): 100.0\n",
      "AUC (Area Under the ROC Curve): 66.66666666666667\n",
      "Brier Score: 24.172315582320188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, brier_score_loss\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Bank': ['Bank A', 'Bank B', 'Bank C', 'Bank D', 'Bank E', 'Bank F', 'Bank G', 'Bank H', 'Bank I', 'Bank J','Bank I','Bank K','Bank 12','Bank 13','Bank 14','Bank 15','Bank 16','Bank 17','Bank 18','Bank 19','Bank 20'],\n",
    "   'Year_2010': [0.02,0.02,0.05,0,0.02,0.05,0,1,0,0.08,0,0.02,0.16,0.015,0.017,0.03,0.22,0.09,0.01,0.06,0.03],\n",
    "    'Year_2011':[0.08,0.1,0.03,0.25,0.04,0.03,0.03,0.54,0.01,0.09,0,0.05,0.39,0.01,0.03,0,0.19,0,0.01,0.02,0.1],\n",
    "    'Year_2012':[0,0,0,0.06,0,0,0.02,0.99,0.04,0.01,0.01,0.15,0.07,0.14,0,0.17,0,0.05,0.02,0.08,0.08],\n",
    "    'Year_2013':[0,0,0,0,0.01,0,0.05,0.06,0,0.03,0,0.01,0,0,0,0,0,0.08,0.09,0.01,0.05],\n",
    "    'Year_2014':[0,0,0,0,0.05,1,1,1,0,0.02,0,0,0,0,0,0,0.01,0,0.5,0.03,0.03],\n",
    "    'Distress': ['Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes']\n",
    "   \n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df[['Year_2010', 'Year_2011','Year_2012','Year_2013','Year_2014']]  # Features\n",
    "y = df['Distress']  # Labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate sensitivity (True Positive Rate)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "sensitivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1]) if sum(confusion[1]) > 0 else 0\n",
    "\n",
    "# Calculate specificity (True Negative Rate)\n",
    "specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1]) if sum(confusion[0]) > 0 else 0\n",
    "\n",
    "# Calculate AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate Brier score\n",
    "brier_score = brier_score_loss(y_test == 'Yes', y_pred_proba)\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity (True Positive Rate):\", sensitivity*100)\n",
    "print(\"Specificity (True Negative Rate):\", specificity*100)\n",
    "print(\"AUC (Area Under the ROC Curve):\", auc*100)\n",
    "print(\"Brier Score:\", brier_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e82135",
   "metadata": {},
   "source": [
    "# Final Output Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37fcfe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Avg Accuracy  Type I Error  Type II Error  Senstivity   \n",
      "0  Before Crisis            60           0.0            100         0.0  \\\n",
      "1  During Crisis            60           0.0            100         0.0   \n",
      "2   After Crisis            60           0.0            100         0.0   \n",
      "\n",
      "   Specificity   AUC  Brier Score  \n",
      "0          100  58.3        22.70  \n",
      "1          100   0.0        24.80  \n",
      "2          100  66.6        24.17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Time':['Before Crisis','During Crisis','After Crisis'],\n",
    "    'Avg Accuracy': [60, 60, 60],\n",
    "    'Type I Error': [0.0, 0, 0],\n",
    "    'Type II Error': [100, 100, 100],\n",
    "    'Senstivity':[0.0,0.0,0.0],\n",
    "    'Specificity': [100,100,100],\n",
    "     'AUC':[58.3 ,0,66.6],\n",
    "     'Brier Score': [22.7, 24.8, 24.17]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Time', 'Avg Accuracy', 'Type I Error','Type II Error','Senstivity','Specificity','AUC','Brier Score'])\n",
    "\n",
    "# Print the Dzzzz\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b69e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
